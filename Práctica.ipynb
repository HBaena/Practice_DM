{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T04:29:56.567049Z",
     "start_time": "2020-04-29T04:29:54.799591Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import pearsonr as correlation \n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T01:17:09.111669Z",
     "start_time": "2020-04-30T01:17:08.148625Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"survey_results_public.csv\")\n",
    "df.describe(include='all')\n",
    "df = df.replace('NaN', np.nan)\n",
    "df = df.replace('nan', np.nan)\n",
    "df = df.replace('JavaScript', 'javascript')\n",
    "def edit_value(item, replace, new_value):\n",
    "    try:\n",
    "        return item.replace(replace, new_value)\n",
    "    except:\n",
    "        return item\n",
    "def remove_c(item):\n",
    "    try: \n",
    "        item = sub('(;|^)C(;|$)', ';C Language;', item)\n",
    "        return sub('^;|;$', '', item)\n",
    "    except:\n",
    "        return item\n",
    "def remove_noise(item):\n",
    "    try:\n",
    "        return sub('\\s*\\(.*\\)\\s*', '', item).strip()\n",
    "    except:\n",
    "        return item\n",
    "# Change JavaScript to javascript to not count into java (sub_str implementation) \n",
    "df['LanguageWorkedWith'] = df['LanguageWorkedWith'].apply(edit_value, args=('JavaScript', 'javascript'))\n",
    "# Change C to C Language to not count into C++,C##, typescript, etc (sub_str implementation) \n",
    "df['LanguageWorkedWith'] = df['LanguageWorkedWith'].apply(remove_c)\n",
    "# \n",
    "df['EdLevel'] = df['EdLevel'].apply(edit_value, \n",
    "                                    args=('Professional degree (JD, MD, etc.)', \n",
    "                                          'Bachelorâ€™s degree (BA, BS, B.Eng., etc.)'))\n",
    "df['EdLevel'] = df['EdLevel'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T01:17:09.706254Z",
     "start_time": "2020-04-30T01:17:09.682966Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:05:51.848771Z",
     "start_time": "2020-04-30T06:05:51.723323Z"
    },
    "code_folding": [
     0,
     12,
     19,
     31,
     46,
     75,
     86,
     95,
     106,
     123,
     211,
     262,
     273,
     326,
     338,
     346,
     387
    ]
   },
   "outputs": [],
   "source": [
    "def is_iterable(obj:object) -> bool:\n",
    "    '''\n",
    "        Determine if a object is iterable or not\n",
    "        return\n",
    "            \n",
    "    '''\n",
    "    try:\n",
    "        iter(obj)\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def new_dict(keys:iter, values:iter) -> dict:\n",
    "    '''\n",
    "        Merge two iterables (keys and values) into a dict\n",
    "        return \n",
    "            dictionary\n",
    "    '''\n",
    "    return {k:v for k, v in zip(keys, values)}\n",
    "def sort_dict(d:dict, reverse:bool=False, \n",
    "              func:callable=lambda item: item[1]) -> dict:\n",
    "    '''\n",
    "        Sort a dict by a given fucntion or according to the value\n",
    "        d       -> dict to sort\n",
    "        reverse -> direction to sort\n",
    "        func    -> sort criteria\n",
    "        \n",
    "        return \n",
    "            sorted dict\n",
    "    '''\n",
    "    return {k: v for k, v in sorted(d.items(), key=func, reverse=reverse)}        \n",
    "def not_nulls(df:pd.DataFrame, *columns) -> pd.DataFrame:\n",
    "    '''\n",
    "        Remove rows with null values\n",
    "        if no columns are passed so dropna is applied to the whole data frame\n",
    "        if columns are passed\n",
    "        are filtered with notnull() func and & operators\n",
    "        return:\n",
    "            Pandas DataFrame\n",
    "    '''\n",
    "    if not columns:\n",
    "        return df[df.notnull()]\n",
    "    filter_ = df[columns[0]].notnull()\n",
    "    for column in columns[1:]:\n",
    "        filter_ &= df[column].notnull() # Avoinding null values\n",
    "    return df[filter_]\n",
    "def describe_to(df:pd.DataFrame, column:str=None, by:str=None, \n",
    "                slice_:slice=slice(0, 8), as_numpy:bool=True) -> np.array:\n",
    "    '''\n",
    "        Convert decribe() DataFrame method to numpy array or pd.serie\n",
    "        Functiion can take only a DataFrame and even 2 DataFrame's columns name\n",
    "        df       -> Pandas DataFrame\n",
    "        column   -> DataFrame's column name\n",
    "        column and by   -> Describe() of column for each unique value of by\n",
    "        slice    -> Slice to return. All values by defaul\n",
    "        as_numpy -> numpy or pd.Series. numpy by defaul\n",
    "        \n",
    "        return sliced Decribe()\n",
    "    '''\n",
    "    if by and not column:\n",
    "        return None\n",
    "    if not column and not by:\n",
    "        return df.describe()[slice_].to_numpy() if as_numpy else df.describe()[slice_]\n",
    "    new_df = df[column]\n",
    "    if not by:\n",
    "        return new_df.describe()[slice_].to_numpy() if as_numpy else new_df.describe()[slice_]\n",
    "    else:\n",
    "        l = []\n",
    "        new_df = not_nulls(df, column, by)\n",
    "        uniques = uniques_values(new_df, by)\n",
    "        for unique in uniques:\n",
    "            filter_ = new_df[by].apply(contain_substr, args=(unique,)) # get certain value even on multimple values rows\n",
    "            f_df = new_df[filter_][column] # filtered dataframe\n",
    "            l.append((unique, f_df.describe()[slice_].to_numpy() if as_numpy else f_df.describe()[slice_]))\n",
    "        return np.array(l)  \n",
    "def five_number_summary(df:pd.DataFrame, column:str, by:str, \n",
    "                        as_numpy:bool=True) -> np.array:\n",
    "    '''\n",
    "        Five numbers summary\n",
    "        df     -> Pandas DataFrame\n",
    "        column          -> DataFrame's column name\n",
    "        column and by   -> Five numbers summary of column for each unique value of by\n",
    "        return:\n",
    "            min, q1, q2 (median), q3, max or a list\n",
    "    '''\n",
    "    return describe_to(df, column, by, slice(3, 8), as_numpy)\n",
    "def contain_substrs(str_:str, *sub_strs) -> bool:\n",
    "    condition = True\n",
    "    length = len(sub_strs)\n",
    "    i = 0\n",
    "    while condition and (i < length):\n",
    "        condition = condition and contain_substr(str_, sub_strs[i])\n",
    "#         print(sub_strs[i], condition)\n",
    "        i += 1\n",
    "    return condition\n",
    "def contain_substr(str_:str, *sub_str) -> bool:\n",
    "    '''\n",
    "        Functions that find a substring on a string with certain characteristics\n",
    "        This function will find \"substr\" inside str\n",
    "        return \n",
    "            True or False\n",
    "    '''\n",
    "    for s in sub_str:\n",
    "        if str_.find(s) != -1:\n",
    "            return True\n",
    "    return False\n",
    "def uniques_values(df:pd.DataFrame, column:str=None) -> list:\n",
    "    '''\n",
    "        This functions take as considerations that columns values could contain multiples \n",
    "        values separated by semicols.\n",
    "        \n",
    "        df     -> Pandas DataFrame\n",
    "        column -> columns to find uniques\n",
    "        \n",
    "        return list of uniques values\n",
    "    '''\n",
    "#     print(df.head(2))\n",
    "    if column:\n",
    "        uniques = df[column].unique().tolist()\n",
    "    else:\n",
    "        uniques = df.unique().tolist()\n",
    "    uniques = ';'.join(str(g) for g in uniques)\n",
    "    return list(set(list(uniques.split(';'))))\n",
    "def hist_box_by(df:pd.DataFrame, column:str, by:str, alias_column:str=None, \n",
    "                alias_by:str=None, boxplottype:str='outliers',\n",
    "                colors:list=None, nbins:int=10,\n",
    "                title:str=None) -> make_subplots:\n",
    "    '''\n",
    "        This function excludes null values on \"column\" and \"by\" doing a simple & functions\n",
    "        df      -> Pandas DataFrame\n",
    "        column  -> Column to analyze\n",
    "        by      -> Column respect to analyze \"column\"\n",
    "        alias_column -> String to show in texts (legend, titles, axis)\n",
    "        alias_by     -> String to show in texts (legend, titles, axis)\n",
    "        boxplottype  -> The way of outliers are handle and showed. \n",
    "                        'all'        -> all points are considerated\n",
    "                        False (bool) -> Only wishkers are considerated\n",
    "                        'suspectedoutliers' -> Only suspected outliers are considerated\n",
    "                        'outliers'   -> Only outliers are considerated (default value)\n",
    "        colors       -> list of colors wich the plots will take. This colors should be representated\n",
    "                        in format:\n",
    "                        hexa   -> '#F33DF5'\n",
    "                        rgb    -> 'rgb(200, 56, 13)'\n",
    "                        rgba   -> 'rgba(20, 189, 12, 90)'\n",
    "                        string -> 'green'\n",
    "                        Thes list can contain mix format.\n",
    "                        colors=['lightgreen', 'rgba(1,200,3,10)', '#FF0034']\n",
    "                        colors=['green', 'lightgreen', 'darkgreen']\n",
    "                        This list must be at least teh same lenght of unique values to plot\n",
    "        nibins       -> Number of bins for the histograms\n",
    "        return plotly figure or None\n",
    "        \n",
    "        exaple 1:\n",
    "        hist_box_by(df, column='StudentsCalifications', by='Gender',\n",
    "                    column_alias='Califications').show()\n",
    "        example 2:\n",
    "        fig = hist_box_by(df, 'dogs_weights', 'kind', boxplottype=False)\n",
    "        fig.show()\n",
    "        example 3:\n",
    "        hist_box_by(df, 'salary', 'Gender', boxplottype='all',\n",
    "                    colors=['#073632', '#7ED388', '#2F668C']).show()\n",
    "    '''\n",
    "    if not alias_column:\n",
    "        alias_column = column\n",
    "    if not alias_by:\n",
    "        alias_by = by\n",
    "    new_df = not_nulls(df, column, by)\n",
    "    if new_df[by].dtype == 'object':\n",
    "        uniques = uniques_values(new_df, by)\n",
    "        func = contain_substr\n",
    "    else:\n",
    "        uniques = new_df[by].unique()\n",
    "        uniques.sort()\n",
    "        func = lambda item, arg: item == arg\n",
    "    fig = make_subplots(\n",
    "        rows=int((len(uniques)*2/4 + 1)), cols=4,\n",
    "        subplot_titles=['Histogram', 'Boxplot'])\n",
    "    if not colors:\n",
    "        colors = [ \"#5E3A6D\", \"#526A2B\", \"#855B96\", \"#938534\", \"#C696DA\", \"#F0B9F4\", \"#F2D2FF\", \"#F4E3B9\", \"#293375\", \"#175565\", \"#717275\",\n",
    "        \"#4E98AC\", \"#EA928D\", \"#A8C6CE\", \"#F5CBC8\", \"#AAE4E6\", \"#4C7CAF\", \"#C6CD51\", \"#BA7847\", \"#E7E884\", \"#F27754\", \n",
    "        \"#92EBE1\", \"#F1CCCC\", \"#D5F1EE\", \"#3930B4\", \"#8B1B1B\", \"#75BCB9\", \"#BF5B97\", \"#B0AEA8\", \"#A07CC9\", \"#F1DBDB\", \"#9ED5F1\"][::-1]    \n",
    "    j = 1\n",
    "    \n",
    "    for i, unique_ in enumerate(uniques):\n",
    "        filter_ = new_df[by].apply(func, args=(unique_,)) # get certain value even on multimple values rows\n",
    "\n",
    "        filtered_df = new_df[filter_] # filtered dataframe\n",
    "#         print(j, (i*2)%2 + 1 + (i*2)%4)\n",
    "#         print(j, (i*2)%2 + 2 + (i*2)%4)\n",
    "        fig.add_trace(\n",
    "            go.Histogram(y=filtered_df[column], name='Histogram' + str(unique_), nbinsy=nbins,\n",
    "                         marker_color=colors[i]),\n",
    "                        row=j, col=(i*2)%2 + (i*2)%4 + 1) # add histogram plot\n",
    "        fig.add_trace(\n",
    "            go.Box(y=filtered_df[column], boxpoints='outliers', name=str(unique_), \n",
    "                        marker_color='#dedbd9',\n",
    "                        line_color=colors[i]\n",
    "                  ),\n",
    "                        row=j, col=(i*2)%2 + (i*2)%4 + 2) # add boxplot\n",
    "        # adding axis labels\n",
    "        fig.update_xaxes(title_text='Count', row=j, col=(i*2)%2 + (i*2)%4 + 1)\n",
    "        fig.update_xaxes(title_text='', row=j, col=(i*2)%2 + (i*2)%4 + 2)\n",
    "        fig.update_yaxes(title_text=alias_column, row=j, col=(i*2)%2 + (i*2)%4 + 1)\n",
    "        j += (0,1)[i%2]\n",
    "    # configurating size, titles and legend\n",
    "    if not title:\n",
    "        title = alias_column + ' by ' + alias_by\n",
    "    fig.update_layout(height=350*int((len(uniques)*2/4 + 1)), width=1400,\n",
    "                      title_text=title,\n",
    "                    showlegend=False)\n",
    "    return fig\n",
    "def hist_by(df:pd.DataFrame, column:str, by:str, alias_column:str=None, \n",
    "                alias_by:str=None, colors:list=None, \n",
    "                nbins:int=10, func:callable=np.sum) -> go.Figure:\n",
    "    '''\n",
    "        This function excludes null values on \"column\" and \"by\" doing a simple & functions\n",
    "        df      -> Pandas DataFrame\n",
    "        column  -> Column to analyze\n",
    "        by      -> Column respect to analyze \"column\"\n",
    "        alias_column -> String to show in texts (legend, titles, axis)\n",
    "        alias_by     -> String to show in texts (legend, titles, axis)\n",
    "        func         -> Criteria for the histogram. Frequency by defaul\n",
    "        colors       -> list of colors wich the plots will take. This colors should be representated\n",
    "                        in format:\n",
    "                        hexa   -> '#F33DF5'\n",
    "                        rgb    -> 'rgb(200, 56, 13)'\n",
    "                        rgba   -> 'rgba(20, 189, 12, 90)'\n",
    "                        string -> 'green'\n",
    "                        Thes list can contain mix format.\n",
    "                        colors=['lightgreen', 'rgba(1,200,3,10)', '#FF0034']\n",
    "                        colors=['green', 'lightgreen', 'darkgreen']\n",
    "                        This list must be at least teh same lenght of unique values to plot\n",
    "        nibins       -> Number of bins for the histograms\n",
    "        return plotly figure or None\n",
    "    '''\n",
    "    if not alias_column:\n",
    "        alias_column = column\n",
    "    if not alias_by:\n",
    "        alias_by = by\n",
    "    new_df = not_nulls(df, column, by)\n",
    "    uniques = uniques_values(new_df, by)\n",
    "    if not colors:\n",
    "        colors = ['#7ED388', '#2F668C', '#ABB392', '#EA7251', '#8501BA', '#09993E', '#BB60C4', '#65F587', '#13CEB7', '#C17B62', '#73A12E', '#344620', '#9B355F', '#B02D36', '#22B407', '#B3391C', '#408C09', '#7846C3', '#548FE2', '#290AFC', '#7C01A8', '#0D8911', '#DEC5CB', '#741BE5', '#5E11F9', '#1C4D07', '#7827A1', '#BFA409', '#F6CB1C', '#DC7AE4', '#97F7ED', '#492CDE', '#CEE30D', '#FAD149', '#BE98C9', '#04D364', '#3D4FF6', '#BB326A', '#4F50A5', '#D02CE0', '#11C68F', '#1863DD', '#0BC224', '#4F2000', '#A38BBC', '#06C5B2']*5\n",
    "    fig = make_subplots(\n",
    "        rows=len(uniques),\n",
    "        subplot_titles=list(uniques))\n",
    "    for i, unique_ in enumerate(uniques):\n",
    "        filter_ = new_df[by].apply(contain_substr, args=(unique_,)) # get certain value even on multimple values rows\n",
    "        filtered_df = new_df[filter_] # filtered dataframe\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=filtered_df[column], name=unique_, \n",
    "                        marker_color=colors[i], nbinsx=nbins\n",
    "                  ), row=i+1, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=alias_column, row=i + 1, col=1)\n",
    "        fig.update_yaxes(title_text=alias_by, row=i + 1, col=1)\n",
    "\n",
    "    # configurating size, titles and legend\n",
    "    fig.update_layout(height=350*len(uniques), width=800,\n",
    "                      title_text=alias_column + ' by ' + alias_by,\n",
    "                    showlegend=False)\n",
    "    return fig\n",
    "def mean_std_median(df:pd.DataFrame, column:str=None, by:str=None, \n",
    "                    as_numpy:bool=True) -> np.array:\n",
    "    '''\n",
    "        mean, standar deviation and median\n",
    "        df     -> Pandas DataFrame\n",
    "        column   -> DataFrame's column name\n",
    "        column and by   -> values of column for each unique value of by\n",
    "        return \n",
    "            maean, std and meadin or a list\n",
    "    '''\n",
    "    return describe_to(df, column, by, [1,2,5], as_numpy)\n",
    "def barplot(df:pd.DataFrame, column:str, alias_column:str=None, \n",
    "            alias_count:str=None, sort:bool=False, \n",
    "            min_:int=0,color:str=None) -> go.Figure:\n",
    "    '''\n",
    "        df     -> Pandas DataFrame\n",
    "        column -> Column name\n",
    "        alias_column -> Text sto show on the plot\n",
    "        sort   -> If value will be showed sorted or not\n",
    "        return \n",
    "            Plotly figure\n",
    "    '''\n",
    "    if not alias_column:\n",
    "        alias_column = column\n",
    "    if not alias_count:\n",
    "        alias_count = 'Count'\n",
    "    new_df = not_nulls(df, column)\n",
    "    uniques = uniques_values(new_df, column)\n",
    "    lengths = {u : new_df[column].apply(contain_substr, args=(u,)).sum() for u in uniques}\n",
    "    if sort:\n",
    "        lengths = sort_dict(lengths, reverse=True if sort=='reverse' else False)\n",
    "    others = sum(lengths.values())\n",
    "    print('Others', others)\n",
    "    lengths = dict(filter(lambda item: item[1] > min_, lengths.items()))\n",
    "    others = others - sum(lengths.values())\n",
    "    if others:\n",
    "        lengths['Others'] = others\n",
    "    if not color or len(color) != 2:\n",
    "        color = ('rgb(158,202,225)', 'rgb(8,48,107)')\n",
    "    fig = go.Figure(data=[go.Bar(x=list(lengths.keys()), y=list(lengths.values()), \n",
    "                                text=list(lengths.values()), textposition='auto',\n",
    "                                textfont=dict(size=18, color=\"black\"))])\n",
    "    fig.update_traces(marker_color=color[0], marker_line_color=color[1],\n",
    "                  marker_line_width=1.5, opacity=0.6)\n",
    "    fig.update_layout(\n",
    "        height=1000,\n",
    "        title='Barchar for ' + alias_column,\n",
    "        xaxis_tickfont_size=14,\n",
    "        yaxis=dict(\n",
    "            title=alias_count,\n",
    "            titlefont_size=16,\n",
    "            tickfont_size=14,\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title=alias_column,\n",
    "            titlefont_size=14,\n",
    "            tickfont_size=12,\n",
    "            tickangle=55\n",
    "        ),\n",
    "        bargap=0.15, # gap between bars of adjacent location coordinates.\n",
    "        bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
    "    )\n",
    "#     fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "    return fig\n",
    "def str_to_float(value:object) -> bool:\n",
    "    '''\n",
    "        Filter for DataFrames that exclude not numeric values\n",
    "        return \n",
    "            True if could e converted to numeric\n",
    "            Fals if don't\n",
    "    '''\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "def remove_not_numeric(df:pd.DataFrame, *columns) -> pd.DataFrame:\n",
    "        \n",
    "        new_df = not_nulls(df, *columns)\n",
    "        if not columns:\n",
    "            return new_df[new_df.apply(str_to_float)]\n",
    "        for column in columns:\n",
    "            new_df = new_df[new_df[column].apply(str_to_float)]            \n",
    "        return new_df\n",
    "def scatter_correlation(df:pd.DataFrame=None, x:str=None, y:str=None,\n",
    "                        aliasx:str=None,  aliasy:str=None,\n",
    "                        text:object=None, color:object='#7ED388') -> (float, go.Figure) :\n",
    "    '''\n",
    "        Pearson correlation calculation and scatter plot unsing x and y\n",
    "        if a dataframe is given, clean not numeric values and null values\n",
    "        df       -> Pandas DataFrame\n",
    "        x and y  -> If a dataframe is given, x and y are columns' names of this\n",
    "                    If not dataframe is given, x and y are arrays\n",
    "        aliasy and alias x -> text for the plot\n",
    "        \n",
    "        return\n",
    "            correlation value and a Plotly Figure with the scatter plot\n",
    "    '''\n",
    "    if df is not None:\n",
    "        if not aliasx:\n",
    "            aliasx = x\n",
    "        if not aliasy:\n",
    "            aliasy = y\n",
    "#         new_df = not_nulls(df, x, y)\n",
    "#         new_df = new_df[new_df[x].apply(str_to_float)]\n",
    "#         new_df = new_df[new_df[y].apply(str_to_float)]\n",
    "        new_df = remove_not_numeric(df, x,y)\n",
    "        x, y = new_df[x].astype('float64'), new_df[y].astype('float64')\n",
    "    if df is None:\n",
    "        if not aliasx:\n",
    "            aliasx = 'x'\n",
    "        if not aliasy:\n",
    "            aliasy = 'y'\n",
    "    if text is None:\n",
    "        text=''\n",
    "    figure = go.Figure(data=[go.Scatter(x=x, y=y, mode='markers', \n",
    "                                        text=text, marker_color=color)]\n",
    "                      )\n",
    "    figure.update_layout(\n",
    "        title=\"Correlation of \" + aliasx + ' and ' + aliasy,\n",
    "        xaxis_title=aliasx,\n",
    "        yaxis_title=aliasy,\n",
    "    )\n",
    "    corr, _ = correlation(x,y)\n",
    "    return corr, figure\n",
    "def ordinal_to_numeric(df:pd.DataFrame, ranks:list, column:str=None, \n",
    "                       as_numpy:bool=True) -> (np.array, dict): \n",
    "    if column:\n",
    "        new_df = df[column]\n",
    "    else:\n",
    "        new_df = df\n",
    "    new_df = not_nulls(new_df)\n",
    "    for k, v in ranks.items():\n",
    "        new_df = new_df.replace(k, v)        \n",
    "    return new_df.astype('float64').to_numpy() if as_numpy else new_df.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T01:18:03.209061Z",
     "start_time": "2020-04-30T01:18:02.377782Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:34:14.228454Z",
     "start_time": "2020-04-30T06:34:13.087324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exericise 1: Compute the five-number summary, the boxplot, the mean, and the standard deviation\n",
    "# for the annual salary per gender.\n",
    "def p_01():\n",
    "    print(five_number_summary(df, column='ConvertedComp', by='Gender', as_numpy=False))\n",
    "    fig = hist_box_by(df, 'ConvertedComp', 'Gender', alias_column='Salary in USD')\n",
    "    # fig.write_image('salary_gender_hist.pdf')\n",
    "    fig.show()\n",
    "    # describe_to(df, 'ConvertedComp', 'Gender', as_numpy=False)\n",
    "p_01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:35:02.770691Z",
     "start_time": "2020-04-30T06:35:00.961670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Compute the five-number summary, the boxplot, the mean, and the standard deviation\n",
    "# for the annual salary per ethnicity.\n",
    "def p_02():\n",
    "    print(five_number_summary(df, column='ConvertedComp', by='Ethnicity', as_numpy=False))\n",
    "    fig = hist_box_by(df, 'ConvertedComp', 'Ethnicity', alias_column='Salary in USD')\n",
    "#     fig.write_image(\"salary_ethnicity_hist.pdf\")\n",
    "    fig.show()\n",
    "p_02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:35:48.981738Z",
     "start_time": "2020-04-30T06:35:43.828986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Compute the five-number summary, the boxplot, the mean, and the standard deviation\n",
    "# for the annual salary per developer type.\n",
    "def p_03():\n",
    "    print(five_number_summary(df, column='ConvertedComp', by='DevType', as_numpy=False))\n",
    "    fig = hist_box_by(df, 'ConvertedComp', 'DevType', alias_column='Salary',\n",
    "                alias_by='developer type')\n",
    "    fig.show()\n",
    "    # fig.write_image(\"salary_devtype_hist.pdf\")\n",
    "p_03()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:46:48.943639Z",
     "start_time": "2020-04-30T06:46:42.308154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 4: Compute the median, mean and standard deviation of \n",
    "# the annual salary per country.\n",
    "def p_04():\n",
    "    print(mean_std_median(df, column='ConvertedComp', by='Country', as_numpy=False))\n",
    "p_04()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:47:00.463457Z",
     "start_time": "2020-04-30T06:46:58.702746Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Exercise 5: Obtain a bar plot with the frequencies of responses for each developer type.\n",
    "def p_05():\n",
    "    barplot(df, 'DevType', alias_column='Developer types').show()\n",
    "p_05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:47:38.007523Z",
     "start_time": "2020-04-30T06:47:37.075053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 6: Plot histograms with 10 bins for the years of \n",
    "# experience with coding per gender.\n",
    "def p_06():\n",
    "    hist_by(df, 'YearsCode', by='Gender', nbins=10, \n",
    "            alias_column='Years coding', \n",
    "            alias_by='Programmers', func=np.sum).show()\n",
    "p_06()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:48:08.910899Z",
     "start_time": "2020-04-30T06:48:07.663778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 7: Plot histograms with 10 bins for the average number of working hours per week, per\n",
    "# developer type.\n",
    "def p_07():\n",
    "    print(five_number_summary(df, 'WorkWeekHrs', 'Gender', as_numpy=False))\n",
    "    hist_box_by(df, 'WorkWeekHrs', by='Gender', nbins=10, \n",
    "                alias_column='Hour worked by week', alias_by='Programmers').show()\n",
    "#     # Seeing that some values makes charts skew, I decided to limit the values to possible week hours \n",
    "#     hist_box_by(df[(df['WorkWeekHrs'] < 24*7)], 'WorkWeekHrs', \n",
    "#                 by='Gender', nbins=10, alias_column='Hour worked by week', \n",
    "#                 alias_by='Programmers').show()\n",
    "#     # Seeing that some values makes charts skew, I decided to limit the values to 12 hour per day\n",
    "#     hist_box_by(df[(df['WorkWeekHrs'] < 12*7)], 'WorkWeekHrs', \n",
    "#                 by='Gender', nbins=10, alias_column='Hour worked by week', \n",
    "#                 alias_by='Programmers').show()\n",
    "p_07()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T01:21:42.826950Z",
     "start_time": "2020-04-30T01:21:40.854963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 8: Plot histograms with 10 bins for the age per gender.\n",
    "def p_08():\n",
    "    print(five_number_summary(df, 'Age', 'Gender', as_numpy=False))\n",
    "    hist_box_by(df, 'Age', by='Gender', nbins=10, \n",
    "                alias_column='Age', alias_by='Programmers').show()\n",
    "#     # Limitting age to greather than 10 years old\n",
    "#     hist_box_by(df[df['Age'] > 10], 'Age', by='Gender', \n",
    "#                 nbins=10, alias_column='Hour worked by week', alias_by='Programmers').show()\n",
    "p_08()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T01:26:37.623371Z",
     "start_time": "2020-04-30T01:26:36.428219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercice 9: Compute the median, mean and standard deviation of the age per programming\n",
    "# language.\n",
    "def p_09():\n",
    "    print(mean_std_median(df, 'Age', 'LanguageWorkedWith', as_numpy=False))\n",
    "#     hist_box_by(df[(df['Age'] > 10) & (df['Age'] < 60)], 'Age', 'LanguageWorkedWith').show()\n",
    "p_09()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:51:16.313813Z",
     "start_time": "2020-04-30T06:51:15.511621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 10: Compute the correlation between years of experience and annual salary.\n",
    "def p_10():\n",
    "    corr, fig = scatter_correlation(df, 'YearsCode', 'ConvertedComp', \n",
    "                                    aliasx='Years coding', aliasy='Salary')\n",
    "    print(corr)\n",
    "    fig.show()\n",
    "p_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:51:46.839290Z",
     "start_time": "2020-04-30T06:51:46.152312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 11: Compute the correlation between the age and the annual salary.\n",
    "# (df['Age'] > 20) & (df['Age'] < 70)\n",
    "def p_11():\n",
    "    corr, fig = scatter_correlation(df,\n",
    "                                    'Age', 'ConvertedComp', \n",
    "                                    aliasx='Age', aliasy='Salary')\n",
    "    print(corr)\n",
    "    fig.show()\n",
    "p_11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:53:53.180279Z",
     "start_time": "2020-04-30T06:53:51.628453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 12: Compute the correlation between educational level and annual salary. In this case,\n",
    "# replace the string of the educational level by an ordinal index (e.g. Primary/elementary\n",
    "# school = 1, Secondary school = 2, and so on).\n",
    "def p_12():\n",
    "    new_df = not_nulls(df, 'EdLevel', 'ConvertedComp')\n",
    "    (uniques_values(new_df, 'EdLevel'))\n",
    "\n",
    "    ranks = {\n",
    "        'I never completed any formal education': 0.1, \n",
    "        'Primary/elementary school': 0.2, \n",
    "        'Secondary school': 0.3, \n",
    "        'Associate degree': 0.4,\n",
    "        'Bachelorâ€™s degree': 0.5, \n",
    "        'Some college/university study without earning a degree': 0.6, \n",
    "        'Masterâ€™s degree': 0.7, \n",
    "        'Other doctoral degree': 0.8\n",
    "    }\n",
    "    # sort_dict(ranks)\n",
    "    y = ordinal_to_numeric(new_df['EdLevel'], ranks)\n",
    "    x = new_df['ConvertedComp']\n",
    "    corr, fig = scatter_correlation(x=x, y=y, text=new_df['EdLevel'], color=y,\n",
    "\n",
    "                                   aliasx='Education level', aliasy='Salary')\n",
    "    labels = list(sort_dict(ranks).keys())\n",
    "    fig.update_yaxes(tickangle=25,\n",
    "\n",
    "\n",
    "                     tickvals=[.1,.2,.3,.4,.5,.6,.7,.8],\n",
    "                     ticktext=list(map(lambda s: s[:15] + '...', labels)))\n",
    "\n",
    "    fig.update_layout(title='Salary according to education')\n",
    "    print(corr)\n",
    "    fig.show()\n",
    "#     fig.write_image('salary_EdLevel.pdf')\n",
    "#     barplot(df, 'EdLevel', sort=True).show()\n",
    "p_12()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T22:25:44.416632Z",
     "start_time": "2020-04-24T22:25:42.485103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 13: Obtain a bar plot with the frequencies of the different programming languages.\n",
    "def p_13():\n",
    "    barplot(df, column='LanguageWorkedWith', \n",
    "            alias_column='Programming languages', sort='reverse').show()\n",
    "p_13()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T06:57:21.499168Z",
     "start_time": "2020-04-30T06:57:21.431427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some code used to create plot ofr the report\n",
    "def others():\n",
    "    # Worked hours respect to education level\n",
    "    new_df = not_nulls(df, 'WorkWeekHrs', 'EdLevel')\n",
    "    new_df = new_df[new_df['WorkWeekHrs'] < 16*7]\n",
    "    new_df = new_df[new_df['WorkWeekHrs'] > 5*7]\n",
    "\n",
    "    ranks = {\n",
    "        'I never completed any formal education': 0.1, \n",
    "        'Primary/elementary school': 0.2, \n",
    "\n",
    "        'Secondary school': 0.3, \n",
    "        'Associate degree': 0.4,\n",
    "        'Bachelorâ€™s degree': 0.5, \n",
    "        'Some college/university study without earning a degree': 0.6, \n",
    "        'Masterâ€™s degree': 0.7, \n",
    "        'Other doctoral degree': 0.8\n",
    "    }\n",
    "    # sort_dict(ranks)\n",
    "    y = ordinal_to_numeric(new_df['EdLevel'], ranks)\n",
    "    x = new_df['WorkWeekHrs']\n",
    "    corr, fig = scatter_correlation(x=x, y=y, text=new_df['EdLevel'], color=y,         \n",
    "                                   aliasx='Education level', aliasy='Worked hours per week')\n",
    "    fig.update_yaxes(tickangle=25,                 \n",
    "                     tickvals=[.1,.2,.3,.4,.5,.6,.7,.8],\n",
    "                     ticktext=list(map(lambda s: s[:15] + '...', labels)))\n",
    "\n",
    "    fig.update_layout(title='Worked hour per week according to education')\n",
    "    # fig.show()\n",
    "    fig.write_image('WorkedHours_EdLevel.pdf')\n",
    "    print(corr)\n",
    "#     -----------------------------------------------\n",
    "    new_df = not_nulls(df, 'LanguageWorkedWith', 'ConvertedComp')\n",
    "    amounts = new_df['LanguageWorkedWith'].apply(\n",
    "        lambda item: item.count(';') + 1)\n",
    "    # Histograms\n",
    "    fig = hist_box_by(new_df, 'ConvertedComp', 'LanguageWorkedWith',\n",
    "                alias_column='Salary in USD', \n",
    "                alias_by='Amount of programming language that they worked with',\n",
    "                nbins=100, title='Salaries in USD by amount of programming languages')\n",
    "    fig.show()\n",
    "    # Sactter plot\n",
    "    corr, fig = scatter_correlation(x=new_df['ConvertedComp'], y=amounts, \n",
    "                                    color=amounts, aliasx='Salaries', \n",
    "                                    aliasy='Amount of programming languages')\n",
    "    print('Correlation')\n",
    "    fig.show()\n",
    "    fig.write_image('salary_amount.pdf')\n",
    "    #     --------------------------------------------------\n",
    "    new_df = not_nulls(df, 'LanguageWorkedWith')\n",
    "    fig = barplot(new_df, 'LanguageWorkedWith', 'Programming languages', \n",
    "                  sort='reverse', color=('#588da8', '#001a33'))\n",
    "    fig.write_image('programminglanguages.pdf')\n",
    "    fig.show()\n",
    "    # --------------------------------------------------------\n",
    "    new_df = not_nulls(df, 'LanguageWorkedWith', 'ConvertedComp')\n",
    "    d = describe_to(new_df[(new_df['ConvertedComp'] < 1000000) & (new_df['ConvertedComp'] > 1000)], 'ConvertedComp', 'LanguageWorkedWith', as_numpy=False)\n",
    "    d = {k: v for k, v in d}\n",
    "    d = sort_dict(d, func=lambda item : item[1]['count'], reverse=True)\n",
    "    figure = go.Figure()\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['mean'],d.values())),\n",
    "                        mode='lines+markers', name='Mean'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['25%'],d.values())),\n",
    "                        mode='lines+markers', name='Firts quartile'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['50%'],d.values())),\n",
    "                        mode='lines+markers', name='Median'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['75%'],d.values())),\n",
    "                        mode='lines+markers', name='Third quartile'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['std'],d.values())),\n",
    "                        mode='lines+markers', name='Standar deviation'\n",
    "                      )\n",
    "    figure.update_layout(\n",
    "        title='Statistics for programming language by amount of programmers',\n",
    "        xaxis=dict(title='Language programming in decendent order according to amount of users'),\n",
    "        yaxis=dict(title='Salary in USD')\n",
    "    )\n",
    "    figure.show()\n",
    "    figure.write_image('statistics_programm.pdf')\n",
    "# ---------------------------------------------------------\n",
    "    ranks = {\n",
    "        'I never completed any formal education': 0.1, \n",
    "        'Primary/elementary school': 0.2,    \n",
    "        'Secondary school': 0.3, \n",
    "        'Associate degree': 0.4,\n",
    "        'Bachelorâ€™s degree': 0.5, \n",
    "        'Some college/university study without earning a degree': 0.6, \n",
    "        'Masterâ€™s degree': 0.7, \n",
    "        'Other doctoral degree': 0.8\n",
    "    }\n",
    "    new_df = not_nulls(df, 'WorkWeekHrs', 'EdLevel')\n",
    "    d = describe_to(new_df[(new_df['WorkWeekHrs'] < 16*7) & (new_df['WorkWeekHrs'] > 6*7)], \n",
    "                    'WorkWeekHrs', 'EdLevel', as_numpy=False)\n",
    "    d = {k: v for k, v in d}\n",
    "    d = {k[:15] + '...': d[k] for k in ranks.keys()}\n",
    "    # d = sort_dict(d, func=lambda item : item[1]['count'], reverse=True)\n",
    "    figure = go.Figure()\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['mean'],d.values())),\n",
    "                        mode='lines+markers', name='Mean'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['25%'],d.values())),\n",
    "                        mode='lines+markers', name='Firts quartile'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['50%'],d.values())),\n",
    "                        mode='lines+markers', name='Median'\n",
    "                      )\n",
    "    figure.add_scatter(\n",
    "                        x=list(d.keys()), \n",
    "                        y=list(map(lambda value: value['75%'],d.values())),\n",
    "                        mode='lines+markers', name='Third quartile'\n",
    "                      )\n",
    "    # figure.add_scatter(\n",
    "    #                     x=list(d.keys()), \n",
    "    #                     y=list(map(lambda value: value['count'],d.values())),\n",
    "    #                     mode='lines+markers', name='Count'\n",
    "    #                   )\n",
    "    figure.update_layout(\n",
    "        title='Statistics for worked hours per week by education',\n",
    "        xaxis=dict(title='Worked hours'),\n",
    "        yaxis=dict(title='Education Level')\n",
    "    )\n",
    "    figure.show()\n",
    "    figure_1 = figure\n",
    "    # figure.write_image('statistics_hours.pdf')\n",
    "    # ----------------------------------------------------------------\n",
    "    fig = barplot(df, 'Gender')\n",
    "    fig.update_yaxes(title='')\n",
    "    fig.update_xaxes(tickangle=25,                 \n",
    "                     tickvals=[0,1,2],\n",
    "                     ticktext=['Non-binary', 'Man', 'Woman'])\n",
    "    fig.update_layout(height=300)\n",
    "    fig.write_image('gender_count.pdf')\n",
    "    fig.show()\n",
    "    # -----------------------------------------------------------------\n",
    "    # df['Gender'] = df['Gender'].apply(edit_value, args=('Non-binary, genderqueer, or gender non-conforminng', 'Non-binary'))\n",
    "    new_df = not_nulls(df, 'Gender', 'DevType')\n",
    "    new_df = new_df[new_df['Gender'].apply(contain_substr, \n",
    "                                  args=('Woman',))]\n",
    "\n",
    "    fig = barplot(new_df, 'DevType', color=('#588da8', '#001a33'), \n",
    "                  alias_column='Developer type')\n",
    "    # fig.data[0].x = list(map(lambda item: item[:20] + '...', fig.data[0].x))\n",
    "    fig.update_layout(height=450, title='Developer type for women')\n",
    "    fig.update_yaxes(title='')\n",
    "\n",
    "    # fig.update_xaxes(tickangle=25,                 \n",
    "    #                  tickvals=[0,1,2],\n",
    "    #                  ticktext=['Non-binary', 'Man', 'Woman'])\n",
    "    fig.write_image('women_devtype.pdf')\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
